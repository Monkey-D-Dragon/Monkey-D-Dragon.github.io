---
layout: post
read_time: true
show_date: true
title:  贝叶斯线性估计和DMD
date:   2023-03-25 13:32:20 -0600
description: 贝叶斯估计理论在DMD中的应用
img: assets/img/posts/20210125/Perceptron.jpg 
tags: [DMD, 贝叶斯估计]
author: Geoffrey Hou
category: DMD
mathjax: yes
toc: yes # leave empty or erase for no TOC
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

最近在学习统计信号处理的估计理论部分，贝叶斯估计理论在DMD中的应用有些需要记录。

MMSE的一般表达式如下：
<center>$\widehat{\boldsymbol{\theta}}=\mathrm{E}[\boldsymbol{\theta}|\boldsymbol{y}]=\int\boldsymbol{\theta}p(\boldsymbol{\theta}|\boldsymbol{y})\mathrm{d}\boldsymbol{\theta}, p(\boldsymbol{\theta}|\boldsymbol{y})=\frac{p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})}{\int p(\boldsymbol{y}|\boldsymbol{\theta}) p(\boldsymbol{\theta})\mathrm{d}\boldsymbol{\theta}}$</center>
需要求多重积分，如果不做任何假设，很难求出闭合表达式。有两种假设可以考虑：联合高斯和线性估计量。

## 联合高斯假设下的线性贝叶斯估计量
### 多维高斯条件PDF
如果$\boldsymbol{x_{k \times 1}}$和$\boldsymbol{y_{l \times 1}}$是联合高斯的，均值矢量是$\left[E[\boldsymbol{x}]^{\mathrm{T}} \quad E[\boldsymbol{y}]^{\mathrm{T}}\right]^{\mathrm{T}}$，协方差是
$
 \boldsymbol{R}=\left[
 \begin{matrix}
   \boldsymbol{R_{\boldsymbol{x} \boldsymbol{x}}} & \boldsymbol{R_{\boldsymbol{x} \boldsymbol{y}}} \\
   \boldsymbol{R_{\boldsymbol{y} \boldsymbol{x}}} & \boldsymbol{R_{\boldsymbol{y} \boldsymbol{y}}}
 \end{matrix}
 \right]
$

那么条件PDF也是高斯的，并且

$$\mathrm{E}[\boldsymbol{y}|\boldsymbol{x}]=\mathrm{E}[\boldsymbol{y}]+\boldsymbol{R_{\boldsymbol{y}\boldsymbol{x}}}\boldsymbol{R_{\boldsymbol{x}\boldsymbol{x}}}^{-1}(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])$$

$$\boldsymbol{R_{\boldsymbol{y}|\boldsymbol{x}}}=\boldsymbol{R_{\boldsymbol{y}\boldsymbol{y}}}-\boldsymbol{R_{\boldsymbol{y}\boldsymbol{x}}}\boldsymbol{R_{\boldsymbol{x}\boldsymbol{x}}}^{-1}\boldsymbol{R_{\boldsymbol{x}\boldsymbol{y}}}$$

### 贝叶斯一般线性模型
数据模型满足
<center>$\boldsymbol{y}=\boldsymbol{H\theta+n}$</center>
其中$\boldsymbol{y}$是$N \times 1$的观测数据矢量，$\boldsymbol{H}$是已知$N \times p$矩阵，$\boldsymbol{\theta}$是$p \times 1$的随机矢量，先验概率PDF满足均值为$\boldsymbol{\mu_{\theta}} $ ，方差为$\boldsymbol{C_{\theta}}$的高斯分布，$\boldsymbol{n}$是$N \times 1$的噪声矢量，PDF满足均值为$\boldsymbol{0}$，方差为$\boldsymbol{C_\theta}$的高斯分布，并且和$\boldsymbol{\theta}$无关。
在$\boldsymbol{y}$和$\boldsymbol{\theta}$联合高斯的条件下，后验PDF也是高斯的。

把$\boldsymbol{H\theta+n}$看作上小节中的$\boldsymbol{x}$，把$\boldsymbol{\theta}$看作上小节中的$\boldsymbol{y}$，有下面的推导：
<center>$$\mathrm{E}[\boldsymbol{x}]=\mathrm{E}[\boldsymbol{H} \boldsymbol{\theta}+\boldsymbol{n}]=\boldsymbol{H}\mathrm{E}[\boldsymbol{\theta}]=\boldsymbol{H}\boldsymbol{\mu}_\theta$$</center>
<center>$$\mathrm{E}[\boldsymbol{y}]=\mathrm{E}[\boldsymbol{\theta}]=\boldsymbol{\mu}_\theta$$</center>
<center>$$\begin{aligned} \boldsymbol{R}_{\boldsymbol{x} \boldsymbol{x}} & =\mathrm{E}\left[(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])^{\mathrm{T}}\right] \\ & =\mathrm{E}\left[\left(\boldsymbol{H} \boldsymbol{\theta}+\boldsymbol{n}-\boldsymbol{H} \boldsymbol{\mu}_{\boldsymbol{\theta}}\right)\left(\boldsymbol{H} \boldsymbol{\theta}+\boldsymbol{n}-\boldsymbol{H} \boldsymbol{\mu}_{\boldsymbol{\theta}}\right)^{\mathrm{T}}\right] \\ & =\mathrm{E}\left[\left(\boldsymbol{H}\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)+\boldsymbol{n}\right)\left(\boldsymbol{H}\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)+\boldsymbol{n}\right)^{\mathrm{T}}\right] \\ & =\boldsymbol{H}\mathrm{E}\left[\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)^{\mathrm{T}}\right] \boldsymbol{H}^{\mathrm{T}}+\mathrm{E}\left[\boldsymbol{n} \boldsymbol{n}^{\mathrm{T}}\right] \\ & =\boldsymbol{H} \boldsymbol{C}_{\boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}+\boldsymbol{C}_{\boldsymbol{n}}\end{aligned}$$</center>
<center>$$
\begin{aligned}
\boldsymbol{R}_{\boldsymbol{y} \boldsymbol{x}} & =\mathrm{E}\left[(\boldsymbol{y}-\mathrm{E}[\boldsymbol{y}])(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])^{\mathrm{T}}\right] \\
& =\mathrm{E}\left[\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)\left(\boldsymbol{H}\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)+\boldsymbol{n}\right)^{\mathrm{T}}\right] \\
& =\boldsymbol{C}_{\boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}
\end{aligned}
$$</center>
<center>$$
\boldsymbol{R_{\boldsymbol{x}\boldsymbol{y}}}=\boldsymbol{H}\boldsymbol{C_\theta}
$$</center>
<center>$$
\mathrm{E}[\boldsymbol{\theta} \mid \boldsymbol{y}]=\boldsymbol{\mu}_{\boldsymbol{\theta}}+\boldsymbol{C}_{\boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}\left(\boldsymbol{H} \boldsymbol{C}_{\boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}+\boldsymbol{C}_{\boldsymbol{n}}\right)^{-\mathbf{1}}\left(\boldsymbol{y}-\boldsymbol{H} \boldsymbol{\mu}_{\boldsymbol{\theta}}\right)
$$</center>
<center>$$
\boldsymbol{R_{\theta|y}}=\boldsymbol{C_\theta}-\boldsymbol{C_\theta}\boldsymbol{H}^{\mathrm{T}}\left(\boldsymbol{H}\boldsymbol{C_\theta}\boldsymbol{H}^{\mathrm{T}}+\boldsymbol{C_n}\right)^{-1}\boldsymbol{H}\boldsymbol{C_\theta}
$$</center>

## 线性贝叶斯估计量
这里没有做联合高斯假设，只限定估计量是线性的。
### LMMSE
#### 标量参数的LMMSE
用$\left.\boldsymbol{y}=\left[\begin{array}{llll}y[0] & y[1\end{array}\right] \quad \cdots \quad y[N-1]\right]^{\mathrm{T}}$表示观测数据矢量，用$\left.\boldsymbol{a}=\left[\begin{array}{llll}a[0] & a[1\end{array}\right] \quad \cdots \quad a[N-1]\right]^{\mathrm{T}}$表示加权系数矢量，标量$\theta$的线性估计量可以表示为

<center>$$
\hat{\theta}=\sum_{i=0}^{N-1} a[i] y[i]+a[N]
$$</center>

通过调整加权系数使得贝叶斯MSE $\operatorname{mse}(\hat{\theta})=\mathrm{E}\left[(\theta-\hat{\theta})^2\right]$最小，即可得到线性最小均方误差估计。

推导过程如下：
首先，贝叶斯MSE对$a[N]$求导得到：
<center>
$$
\begin{aligned}
\frac{\partial}{\partial a[N]} \mathrm{E}\left[(\theta-\hat{\theta})^2\right] & =\frac{\partial}{\partial a[N]} \mathrm{E}\left[\left(\theta-\sum_{i=0}^{N-1} a[i] y[i]-a[N]\right)^2\right] \\
& =-2 \mathrm{E}\left[\theta-\sum_{i=0}^{N-1} a[i] y[i]-a[N]\right]
\end{aligned}
$$
</center>
令其为零，得到$a[N]=\mathrm{E}[\theta]-\sum_{i=0}^{N-1} a[i] \mathrm{E}[y[i]]$。这样$\operatorname{mse}(\hat{\theta})$可以写成矩阵形式
<center>
$\operatorname{mse}(\hat{\theta})=\boldsymbol{a}^{\mathrm{T}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}} \boldsymbol{a}-\boldsymbol{a}^{\mathrm{T}} \boldsymbol{R}_{\boldsymbol{y} \theta}-\boldsymbol{R}_{\theta \boldsymbol{y}} \boldsymbol{a}+\boldsymbol{R}_{\theta \theta}$
</center>
对$\boldsymbol{a}$求导，
<center>
$$
\frac{\partial \mathrm{mse}(\hat{\theta})}{\partial \boldsymbol{a}}=2 \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}} \boldsymbol{a}-2 \boldsymbol{R}_{\boldsymbol{y} \theta}
$$
</center>
令其为零，得到
<center>
$$
\boldsymbol{a}=\boldsymbol{R_{\boldsymbol{y}\boldsymbol{y}}}{ }^{-1}\boldsymbol{R_{\boldsymbol{y}\boldsymbol{\theta}}}
$$
</center>
<center>
$$
\begin{aligned}
\hat{\theta} & =\boldsymbol{a}^{\mathrm{T}} \boldsymbol{y}+a[N] \\
& =\boldsymbol{R}_{\boldsymbol{y} \theta}{ }^{\mathrm{T}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}{ }^{-\mathbf{1}} \boldsymbol{y}+\mathrm{E}[\theta]-\boldsymbol{R}_{\boldsymbol{y} \theta}{ }^{\mathrm{T}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}{ }^{-\mathbf{1}} \mathrm{E}[\boldsymbol{y}] \\
& =\mathrm{E}[\theta]+\boldsymbol{R}_{\theta \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}{ }^{-\mathbf{1}}(\boldsymbol{y}-\mathrm{E}[\boldsymbol{y}])
\end{aligned}
$$
</center>
这样就得到标量参数的LMMSE，并且其最小贝叶斯MSE为
<center>
$$
\operatorname{mse}(\hat{\theta})=R_{\theta \theta}-\boldsymbol{R}_{\theta \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}{ }^{-\mathbf{1}} \boldsymbol{R}_{\boldsymbol{y} \theta}
$$
</center>

#### 矢量参数的LMMSE
对标量参数的结果做扩展，对矢量参数中的第$i$个参数，应用上面的结果有
<center>
$$
\hat{\theta}_i=\mathrm{E}\left[\theta_i\right]+\boldsymbol{R}_{\theta_i \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y}}{ }^{-\mathbf{1}}(\boldsymbol{y}-\mathrm{E}[\boldsymbol{y}]), i=1,2, \cdots, p
$$
</center>
<center>
$$
\operatorname{mse}\left(\hat{\theta}_i\right)=R_{\theta_i \theta_i}-\boldsymbol{R}_{\theta_i \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} y}{ }^{-1} \boldsymbol{R}_{\boldsymbol{y} \theta_i}, i=1,2, \cdots, p
$$
</center>
组成矢量参数有
<center>
$$
\begin{aligned}
\widehat{\boldsymbol{\theta}} & =\left[\begin{array}{c}
\mathrm{E}\left[\theta_1\right] \\
\mathrm{E}\left[\theta_2\right] \\
\vdots \\
\mathrm{E}\left[\theta_p\right]
\end{array}\right]+\left[\begin{array}{c}
\boldsymbol{R}_{\theta_1 \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}^{-\mathbf{1}}(\boldsymbol{y}-\mathrm{E}[\boldsymbol{y}]) \\
\boldsymbol{R}_{\theta_2 \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}^{-\mathbf{1}}(\boldsymbol{y}-\mathrm{E}[\boldsymbol{y}]) \\
\vdots \\
\boldsymbol{R}_{\theta_p \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}^{-\mathbf{1}}(\boldsymbol{y}-\mathrm{E}[\boldsymbol{y}])
\end{array}\right] \\
& =\left[\begin{array}{c}
\mathrm{E}\left[\theta_1\right] \\
\mathrm{E}\left[\theta_2\right] \\
\vdots \\
\mathrm{E}\left[\theta_p\right]
\end{array}\right]+\left[\begin{array}{c}
\boldsymbol{R}_{\theta_1 \boldsymbol{y}} \\
\boldsymbol{R}_{\theta_2 \boldsymbol{y}} \\
\vdots \\
\boldsymbol{R}_{\theta_p \boldsymbol{y}}
\end{array}\right] \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{- 1}}{ }^{-1}(\boldsymbol{y}[\boldsymbol{y}]) \\
& =\mathrm{E}[\boldsymbol{\theta}]+\boldsymbol{R}_{\boldsymbol{\theta} \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}^{-\mathbf{1}}(\boldsymbol{y}-\mathrm{E}[\boldsymbol{y}])
\end{aligned}
$$
</center>
<center>
$$
\operatorname{mse}(\widehat{\boldsymbol{\theta}})=\boldsymbol{R}_{\boldsymbol{\theta} \boldsymbol{\theta}}-\boldsymbol{R}_{\boldsymbol{\theta} y} \boldsymbol{R}_{\boldsymbol{y}{ }^{-1}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{\theta}}
$$
</center>

这就是矢量参数LMMSE的原始表达式，仅限定估计量是线性的：
<center>
$$
\widehat{\boldsymbol{\theta}}=\mathrm{E}[\boldsymbol{\theta}]+\boldsymbol{R}_{\boldsymbol{\theta} \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}{ }^{\mathbf{1}}(\boldsymbol{y}-\mathrm{E}[\boldsymbol{y}])
$$
</center>

利用线性贝叶斯的结论：
<center>
$$
\mathrm{E}[\boldsymbol{y}]=\boldsymbol{H} \mathrm{E}[\boldsymbol{\theta}]
$$
</center>
<center>
$$
\boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}=\boldsymbol{H} \boldsymbol{C}_{\boldsymbol{\theta} \boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}+\boldsymbol{C}_{\boldsymbol{n} \boldsymbol{n}}
$$
</center>
<center>
$$
\boldsymbol{R}_{\boldsymbol{\theta} \boldsymbol{y}}=\boldsymbol{C}_{\boldsymbol{\theta} \boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}
$$
</center>
代入原始表达式得到：
<center>
$$
\begin{aligned}
\widehat{\boldsymbol{\theta}} & =\mathrm{E}[\boldsymbol{\theta}]+\boldsymbol{C}_{\boldsymbol{\theta} \boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}\left(\boldsymbol{H} \boldsymbol{C}_{\boldsymbol{\theta} \boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}+\boldsymbol{C}_{\boldsymbol{n} \boldsymbol{n}}\right)^{-\mathbf{1}}(\boldsymbol{y}-\boldsymbol{H} \mathrm{E}[\boldsymbol{\theta}]) \\
& =\mathrm{E}[\boldsymbol{\theta}]+\left(\boldsymbol{H}^{\mathrm{T}} \boldsymbol{C}_{\boldsymbol{n} n}{ }^{-1} \boldsymbol{H}+\boldsymbol{C}_{\boldsymbol{\theta} \boldsymbol{\theta}}{ }^{-1}\right)^{-\mathbf{1}} \boldsymbol{H}^{\mathrm{T}} \boldsymbol{C}_{\boldsymbol{n} n}{ }^{-\boldsymbol{1}}(\boldsymbol{y}-\boldsymbol{H} \mathrm{E}[\boldsymbol{\theta}])
\end{aligned}
$$
</center>

## LMMSE均衡
### 数据模型
用$y$表示接收信号，用$x$表示零均值$\mathrm{E}[\boldsymbol{x}]=\mathbf{0}$，能量归一化并且元素之间相互独立的发送信号，$n$表示加性高斯白噪声，$H$为信道估计结果，这样接收信号可以表示为
<center>
$$
\boldsymbol{y=Hx+n}
$$
</center>
### 最佳均衡矩阵
#### 矢量LMMSE
利用结论
<center>
$$
\widehat{\boldsymbol{\theta}}=\mathrm{E}[\boldsymbol{\theta}]+\left(\boldsymbol{H}^{\mathrm{T}} \boldsymbol{C}_{\boldsymbol{n} n}{ }^{-1} \boldsymbol{H}+\boldsymbol{C}_{\boldsymbol{\theta} \boldsymbol{\theta}}^{-1}\right)^{-1} \boldsymbol{H}^{\mathrm{T}} \boldsymbol{C}_{\boldsymbol{n} n}^{-1}(\boldsymbol{y}-\boldsymbol{H} \mathrm{E}[\boldsymbol{\theta}])
$$
</center>
其中的$\theta$对应均衡中的$x$，直接替换可以得到
<center>
$$
\hat{\boldsymbol{x}}=\mathrm{E}[\boldsymbol{x}]+\left(\boldsymbol{H}^{\mathrm{T}} \boldsymbol{C}_{\boldsymbol{n} n}^{-1} \boldsymbol{H}+\boldsymbol{C}_{\boldsymbol{x} \boldsymbol{x}}^{-1}\right)^{-1} \boldsymbol{H}^{\mathrm{T}} \boldsymbol{C}_{\boldsymbol{n} n}^{-1}(\boldsymbol{y}-\boldsymbol{H E}[\boldsymbol{x}])
$$
</center>
如果考虑到发送信号是零均值的，可以去掉均值项，得到
<center>
$$
\widehat{\boldsymbol{x}}=\left(\boldsymbol{H}^{\mathrm{T}} \boldsymbol{C}_{\boldsymbol{n} n}{ }^{-1} \boldsymbol{H}+\boldsymbol{C}_{\boldsymbol{x} \boldsymbol{x}}^{-1}\right)^{-\boldsymbol{1}} \boldsymbol{H}^{\mathrm{T}} \boldsymbol{C}_{\boldsymbol{n} n}{ }^{-1} \boldsymbol{y}
$$
</center>
这样就得到最佳均衡矩阵
<center>
$$
\boldsymbol{W}=\left(\boldsymbol{H}^{\mathrm{T}} \boldsymbol{C}_{n n}{ }^{-1} \boldsymbol{H}+\boldsymbol{C}_{x x}{ }^{-1}\right)^{-1} \boldsymbol{H}^{\mathrm{T}} \boldsymbol{C}_{n n}{ }^{-1}
$$
</center>
如果再加上发送信号是能量归一化的和噪声白化的条件，可以进一步简化为：
<center>
$$
\boldsymbol{W}=\left(\boldsymbol{H}^{\mathrm{T}} \boldsymbol{H}+\boldsymbol{I}\right)^{-\mathbf{1}} \boldsymbol{H}^{\mathrm{T}}
$$
</center>

#### 正交原理
正交原理也叫投影定理，可以描述为：在利用数据样本的线性组合来估计一个随机变量的时候，当误差和每一个数据样本正交时，可以得到最佳估计量。
根据MMSE准则：
<center>
$$
\widehat{\boldsymbol{x}}=\underset{\widehat{x}}{\operatorname{argmin}}\left\{E\left[\|\widehat{\boldsymbol{x}}-\boldsymbol{x}\|^2\right]\right\}
$$
</center>
在线性MIMO均衡中，有$\widehat{x}=W \boldsymbol{y}$，这样上式可以表示为：
<center>
$$
\hat{\boldsymbol{x}}=\underset{\boldsymbol{W}}{\operatorname{argmin}}\left\{\mathrm{E}\left[\|\boldsymbol{W} \boldsymbol{y}-\boldsymbol{x}\|^2\right]\right\}
$$
</center>
把正交原理用于MIMO均衡中，可以描述为：当误差$\widehat{x}-x$和每个接收信号$y$正交时，可以得到最佳估计量：
<center>
$$
\begin{aligned}
& \mathrm{E}[(\hat{x}-\boldsymbol{x}) \boldsymbol{y}]=\mathbf{0} \\
& \rightarrow \mathrm{E}[(\hat{x}-\boldsymbol{x}) \boldsymbol{y}]=\mathbf{0} \\
& \rightarrow \mathrm{E}[(\boldsymbol{W} \boldsymbol{y}-\boldsymbol{x}) \boldsymbol{y}]=\mathbf{0} \\
& \rightarrow \boldsymbol{W} \cdot \mathrm{E}[\boldsymbol{y} \boldsymbol{y}]=\mathrm{E}[\boldsymbol{x} \boldsymbol{y}] \\
& \rightarrow \boldsymbol{W} \cdot \boldsymbol{R}_{\boldsymbol{y} y}=\boldsymbol{R}_{\boldsymbol{x y}} \\
& \rightarrow \boldsymbol{W}=\boldsymbol{R}_{\boldsymbol{x} \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}{ }^{-1}
\end{aligned}
$$
</center>
这就是线性MIMO均衡在MMSE准则下的最佳均衡矩阵的原始表达式：
<center>
$$
\boldsymbol{W}=\boldsymbol{R_{xy}}\boldsymbol{R_{yy}}{ }^{-1}
$$
</center>
